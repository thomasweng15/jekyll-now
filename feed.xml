<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.4">Jekyll</generator><link href="http://thomasweng.com/feed.xml" rel="self" type="application/atom+xml" /><link href="http://thomasweng.com/" rel="alternate" type="text/html" /><updated>2019-08-31T22:34:44+00:00</updated><id>http://thomasweng.com/feed.xml</id><title type="html">Thomas Weng</title><subtitle>adventures in computing, productivity, and ?</subtitle><entry><title type="html">How to install ROS drivers for Azure Kinect on Ubuntu 16.04</title><link href="http://thomasweng.com/azure_kinect_1604_ros/" rel="alternate" type="text/html" title="How to install ROS drivers for Azure Kinect on Ubuntu 16.04" /><published>2019-08-31T00:00:00+00:00</published><updated>2019-08-31T00:00:00+00:00</updated><id>http://thomasweng.com/azure_kinect_1604_ros</id><content type="html" xml:base="http://thomasweng.com/azure_kinect_1604_ros/">&lt;p&gt;Following up from my previous post on &lt;a href=&quot;../azure_kinect_1604&quot;&gt;installing the Azure Kinect SDK on Ubuntu 16.04&lt;/a&gt;, this post provides instructions for setting up ROS drivers for the Azure Kinect. These instructions apply for ROS kinetic and Ubuntu 16.04.&lt;/p&gt;

&lt;p&gt;The credit for figuring out these steps goes to &lt;a href=&quot;https://www.ri.cmu.edu/ri-people/kevin-zhang/&quot;&gt;Kevin Zhang&lt;/a&gt;!&lt;/p&gt;

&lt;h1 id=&quot;installation-steps&quot;&gt;Installation steps&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;Install the Azure Kinect SDK executables on your path so they can be found by ROS.
    &lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;path/to/Azure-Kinect-Sensor-SDK/build
&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;ninja &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Clone the official ROS driver into a catkin workspace.
    &lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;catkin_ws/src
&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; git clone https://github.com/microsoft/Azure_Kinect_ROS_Driver.git
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Make minor edits to the codebase. If you were to build the workspace now, you would get errors relating to &lt;code class=&quot;highlighter-rouge&quot;&gt;std::atomic&lt;/code&gt; syntax.&lt;/p&gt;

    &lt;p&gt;To fix this, open &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;repo&amp;gt;/include/azure_kinect_ros_driver/k4a_ros_device.h&lt;/code&gt; and convert all instances of &lt;code class=&quot;highlighter-rouge&quot;&gt;std::atomic_TYPE&lt;/code&gt; type declarations to &lt;code class=&quot;highlighter-rouge&quot;&gt;std::atomic&amp;lt;TYPE&amp;gt;&lt;/code&gt;. Below is a diff of the edits I made.&lt;/p&gt;
    &lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;@@&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;117&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;117&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;@@&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;K4AROSDevice&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;volatile&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;running_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
 
  &lt;span class=&quot;c1&quot;&gt;// Last capture timestamp for synchronizing playback capture and imu thread&lt;/span&gt;
       &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;atomic_int64_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last_capture_time_usec_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
       &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;atomic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int64_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last_capture_time_usec_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
 
  &lt;span class=&quot;c1&quot;&gt;// Last imu timestamp for synchronizing playback capture and imu thread&lt;/span&gt;
       &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;atomic_uint64_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last_imu_time_usec_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
       &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;atomic_bool&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;imu_stream_end_of_file_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
       &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;atomic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;uint64_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last_imu_time_usec_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
       &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;atomic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;imu_stream_end_of_file_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
 
  &lt;span class=&quot;c1&quot;&gt;// Threads&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;kr&quot;&gt;thread&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frame_publisher_thread_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Build the catkin workspace with either &lt;code class=&quot;highlighter-rouge&quot;&gt;catkin_make&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;catkin build&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Copy the libdepthengine and libstdc++ binaries that you placed in the &lt;code class=&quot;highlighter-rouge&quot;&gt;Azure_Kinect_SDK/build/bin&lt;/code&gt; folder from my &lt;a href=&quot;../azure_kinect_1604&quot;&gt;previous post&lt;/a&gt; in your catkin workspace.
    &lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;cp &lt;/span&gt;path/to/Azure_Kinect_SDK/build/bin/libdepthengine.so.1.0 path/to/catkin_ws/devel/lib/
&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;cp &lt;/span&gt;path/to/Azure_Kinect_SDK/build/bin/libstdc++.so.6 path/to/catkin_ws/devel/lib/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;You will have to do this whenever you do a clean build of your workspace.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Copy udev rules from the ROS driver repo to your machine.
    &lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;cp&lt;/span&gt; /path/to/Azure_Kinect_ROS_Driver/scripts/99-k4a.rules /etc/udev/rules.d/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;Unplug and replug your sensor into the machine after copying the file over.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Source your built workspace and launch the driver.
    &lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;source &lt;/span&gt;path/to/catkin_ws/devel/setup.bash
&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; roslaunch azure_kinect_ros_driver driver.launch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;Note that there are parameters you can adjust in the driver launch file, e.g. fps, resolution, etc.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Run Rviz and you should be able to open Image and PointCloud2 widgets that read topics from the sensor!&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;cntr&quot;&gt;
  &lt;img src=&quot;../assets/19-08-29_1.png&quot; /&gt;
  &lt;div class=&quot;caption&quot;&gt;
    Screenshot from RViz
  &lt;/div&gt;
&lt;/div&gt;</content><author><name>Thomas Weng</name></author><category term="robotics" /><summary type="html">Following up from my previous post on installing the Azure Kinect SDK on Ubuntu 16.04, this post provides instructions for setting up ROS drivers for the Azure Kinect. These instructions apply for ROS kinetic and Ubuntu 16.04.</summary></entry><entry><title type="html">Terminal tips</title><link href="http://thomasweng.com/terminal_tips/" rel="alternate" type="text/html" title="Terminal tips" /><published>2019-08-27T00:00:00+00:00</published><updated>2019-08-27T00:00:00+00:00</updated><id>http://thomasweng.com/terminal_tips</id><content type="html" xml:base="http://thomasweng.com/terminal_tips/">&lt;p&gt;The terminal is an essential tool,&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; but also one whose tasks are most easily automated and optimized.&lt;/p&gt;

&lt;p&gt;Most of the time spent on the command line is on non-value-adding tasks, like moving files around, executing programs, installing dependencies, and checking system status.&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;
These tasks are necessary, but do not end up in your final deliverable, i.e. a publication, code, or other project output.&lt;/p&gt;

&lt;p&gt;Therefore, you should aim to spend as little time in the terminal as possible, focusing instead on value-adding tasks like writing programs, analyzing data, making visualizations, etc.&lt;/p&gt;

&lt;p&gt;Here are some ways to automate or speed up terminal tasks. I’m assuming you use bash, but the items here are applicable to most terminals.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#1-shorten-commands-using-aliases-and-scripts&quot;&gt;Shorten commands using aliases and scripts&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2-use-reverse-i-search-to-find-past-commands&quot;&gt;Use reverse-i-search to find past commands&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#3-check-system-status-using-htop&quot;&gt;Check system status using htop&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#4-split-one-terminal-into-multiple-with-tmux&quot;&gt;Split one terminal into several with tmux&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#5-download-files-faster-using-aria2&quot;&gt;Download files faster using aria2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#6-set-up-key-based-authentication-for-ssh-and-github&quot;&gt;Set up key-based authentication for ssh and Github&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#7-try-out-other-terminals&quot;&gt;Try out other terminals&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;1-shorten-commands-using-aliases-and-scripts&quot;&gt;1. Shorten commands using aliases and scripts&lt;/h1&gt;

&lt;p&gt;This one seems obvious, but if you run the same set of commands often, turn them into &lt;a href=&quot;https://www.digitalocean.com/community/tutorials/an-introduction-to-useful-bash-aliases-and-functions&quot;&gt;aliases&lt;/a&gt;. 
I use aliases for computers that I ssh into often, e.g.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;alias hostname&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;ssh &amp;lt;username&amp;gt;@&amp;lt;hostname&amp;gt;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Another use case is for aliases is to shorten series of commands, like navigating to a directory and running a script.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;alias &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;intera&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;cd ~/catkin_ws &amp;amp;&amp;amp; source intera.sh&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If a series of commands is longer or more complicated (e.g. building and running code), it may be better to turn it into a &lt;a href=&quot;https://www.digitalocean.com/community/tutorial_series/an-introduction-to-shell-scripting&quot;&gt;shell script&lt;/a&gt;, which will allow you to take advantage of for loops, command line arguments, etc.&lt;/p&gt;

&lt;h1 id=&quot;2-use-reverse-i-search-to-find-past-commands&quot;&gt;2. Use reverse-i-search to find past commands&lt;/h1&gt;

&lt;p&gt;Related to the first point, avoid typing out commands, especially if you have typed a similar one already. Besides using tab-autocompleting aggressively, I also use &lt;a href=&quot;https://lifehacker.com/ctrl-r-to-search-and-other-terminal-history-tricks-278888&quot;&gt;reverse-i-search&lt;/a&gt; all the time to search my command history. Activate reverse-i-search using &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl+r&lt;/code&gt; and then type in a query to find matches. Hit &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl+r&lt;/code&gt; again to find the next match.&lt;/p&gt;

&lt;div class=&quot;cntr&quot;&gt;
  &lt;img src=&quot;https://media.giphy.com/media/lOsUAIXzpcK3nr6Tej/giphy.gif&quot; /&gt;
  &lt;div class=&quot;caption&quot;&gt;
  Demonstrating reverse-i-search.
  &lt;/div&gt;
&lt;/div&gt;

&lt;h1 id=&quot;3-check-system-status-using-htop&quot;&gt;3. Check system status using htop&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://hisham.hm/htop/&quot;&gt;htop&lt;/a&gt; is an improved version of the &lt;code class=&quot;highlighter-rouge&quot;&gt;top&lt;/code&gt; command, with colors, better navigation, and other features.&lt;/p&gt;

&lt;div class=&quot;cntr&quot;&gt;
  &lt;img src=&quot;../assets/19-08-27_1.png&quot; /&gt;
  &lt;div class=&quot;caption&quot;&gt;
  Screenshot of htop.
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Besides checking system usage, I also use this to find (&lt;code class=&quot;highlighter-rouge&quot;&gt;F4&lt;/code&gt;) and kill (&lt;code class=&quot;highlighter-rouge&quot;&gt;F9&lt;/code&gt;) processes as root (&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo htop&lt;/code&gt;).&lt;/p&gt;

&lt;h1 id=&quot;4-split-one-terminal-into-several-with-tmux&quot;&gt;4. Split one terminal into several with tmux&lt;/h1&gt;

&lt;p&gt;Use &lt;a href=&quot;https://github.com/tmux/tmux/wiki&quot;&gt;tmux&lt;/a&gt; to create and switch between multiple terminal panes within one window.&lt;/p&gt;

&lt;div class=&quot;cntr&quot;&gt;
  &lt;img src=&quot;https://media.giphy.com/media/lquszCDcatgZlrC06g/giphy.gif&quot; /&gt;
  &lt;div class=&quot;caption&quot;&gt;
  Demonstrating how to split panes with tmux. Note that my keybindings are different from the tmux defaults.
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Another benefit to tmux is that these terminals will persist even if your ssh connection drops. Simply run &lt;code class=&quot;highlighter-rouge&quot;&gt;tmux attach&lt;/code&gt; after ssh-ing back in to return to your panes.&lt;/p&gt;

&lt;h1 id=&quot;5-download-files-faster-using-aria2&quot;&gt;5. Download files faster using aria2&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://aria2.github.io/&quot;&gt;aria2&lt;/a&gt; is an alternative to &lt;code class=&quot;highlighter-rouge&quot;&gt;wget&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;curl&lt;/code&gt; that parallelizes downloads:&lt;/p&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; aria2c &lt;span class=&quot;nt&quot;&gt;-x8&lt;/span&gt; &amp;lt;URL&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-xN&lt;/code&gt; specifies how many connections to open for parallelization.&lt;/p&gt;

&lt;h1 id=&quot;6-set-up-key-based-authentication-for-ssh-and-github&quot;&gt;6. Set up key-based authentication for ssh and Github&lt;/h1&gt;

&lt;p&gt;Instead of typing your password each time you ssh or push/pull from Github, use key-based authentication. It only takes a few minutes and has the dual benefit of being easier and more secure than password authentication.&lt;/p&gt;

&lt;p&gt;To set up key-based authentication for ssh, see this DigitalOcean post: &lt;a href=&quot;https://www.digitalocean.com/community/tutorials/how-to-set-up-ssh-keys--2&quot;&gt;How To Set Up SSH Keys&lt;/a&gt;. You’ll need to do this once per computer you want to &lt;code class=&quot;highlighter-rouge&quot;&gt;ssh&lt;/code&gt; into. For Github, follow the steps outlined here: &lt;a href=&quot;https://help.github.com/en/articles/connecting-to-github-with-ssh&quot;&gt;Connecting to Github with SSH&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;7-try-out-other-terminals&quot;&gt;7. Try out other terminals&lt;/h1&gt;

&lt;p&gt;You can also explore beyond bash and try terminals with more features. I use zsh as my default shell with plugins for jumping between directories, better autocomplete, etc. If you’re interested in zsh, check out these articles on how to get started: &lt;a href=&quot;https://github.com/robbyrussell/oh-my-zsh/wiki/Articles&quot;&gt;Articles from the Oh My Zsh wiki&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;Many thanks to &lt;a href=&quot;http://www.andrew.cmu.edu/user/abhijatb/&quot;&gt;Cherie Ho&lt;/a&gt; for editing this post and introducing me to zsh, &lt;a href=&quot;https://homes.cs.washington.edu/~lrperlmu/&quot;&gt;Leah Perlmutter&lt;/a&gt; for introducing me to reverse-i-search, &lt;a href=&quot;https://personalrobotics.cs.washington.edu/people/&quot;&gt;Rosario Scalise&lt;/a&gt; for tmux, and &lt;a href=&quot;http://www.andrew.cmu.edu/user/abhijatb/&quot;&gt;Abhijat Biswas&lt;/a&gt; for aria2!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Footnotes&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;If you’re a beginner with the terminal, &lt;a href=&quot;https://swcarpentry.github.io/shell-novice/reference/&quot;&gt;this reference&lt;/a&gt; from Software Carpentry is a good starting point. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;I consider working in a terminal-based editor like vim different from being on the command line itself. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Thomas Weng</name></author><category term="programming" /><category term="productivity" /><summary type="html">The terminal is an essential tool,1 but also one whose tasks are most easily automated and optimized. If you’re a beginner with the terminal, this reference from Software Carpentry is a good starting point. &amp;#8617;</summary></entry><entry><title type="html">How to install the Azure Kinect SDK on Ubuntu 16.04</title><link href="http://thomasweng.com/azure_kinect_1604/" rel="alternate" type="text/html" title="How to install the Azure Kinect SDK on Ubuntu 16.04" /><published>2019-07-19T00:00:00+00:00</published><updated>2019-07-19T00:00:00+00:00</updated><id>http://thomasweng.com/azure_kinect_1604</id><content type="html" xml:base="http://thomasweng.com/azure_kinect_1604/">&lt;p&gt;Microsoft recently released the &lt;a href=&quot;https://azure.microsoft.com/en-us/services/kinect-dk/&quot;&gt;Azure Kinect DK&lt;/a&gt; sensor, a $399 developer-oriented sensor kit for robotics and mixed reality applications. 
The kit’s SDK officially supports Windows and Linux 18.04.
I’ve managed to get the v1.1 SDK working on Ubuntu 16.04, and have documented the steps below.&lt;/p&gt;

&lt;h1 id=&quot;why-downgrade-to-ubuntu-1604&quot;&gt;Why downgrade to Ubuntu 16.04?&lt;/h1&gt;

&lt;p&gt;Many of the robots I work with or have worked with are tied to Ubuntu 16.04, e.g. the Rethink Robotics Sawyer robot, as well as the PR2.
Upgrading the robot hardware to 18.04 is difficult and would break existing projects.
Although upgrading to 18.04 will eventually be necessary, it is helpful to have the Azure Kinect DK working on 16.04 in the meantime.&lt;/p&gt;

&lt;h1 id=&quot;installation-steps&quot;&gt;Installation steps&lt;/h1&gt;
&lt;p&gt;These steps worked for me on an existing Ubuntu 16.04 installation, not a fresh one, so your mileage may vary.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Download the v1.1 SDK from Github.
    &lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; git clone https://github.com/microsoft/Azure-Kinect-Sensor-SDK/tree/release/1.1.x
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Install dependencies using the provided script.
    &lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; bash ./Azure-Kinect-Sensor-SDK/scripts/bootstrap-ubuntu.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Follow the build steps in &lt;a href=&quot;https://github.com/microsoft/Azure-Kinect-Sensor-SDK/blob/release/1.1.x/docs/building.md&quot;&gt;https://github.com/microsoft/Azure-Kinect-Sensor-SDK/blob/release/1.1.x/docs/building.md&lt;/a&gt;.
    &lt;ul&gt;
      &lt;li&gt;If you get a CMake error, you may need to upgrade CMake&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.
        &lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;go&quot;&gt;% Download and extract cmake 3.14.5
&lt;/span&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; ~/temp
&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; ~/temp
&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; wget https://cmake.org/files/v3.14/cmake-3.14.5.tar.gz
&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;tar&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-xzvf&lt;/span&gt; cmake-3.14.5.tar.gz
&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;cmake-3.14.5/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
        &lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;go&quot;&gt;% Install extracted source
&lt;/span&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; ./bootstrap
&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; make &lt;span class=&quot;nt&quot;&gt;-j4&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;make &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; cmake &lt;span class=&quot;nt&quot;&gt;--version&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;If you get a libsoundio error, you may need to install jack-tools.
        &lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;jack-tools
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Get a copy of the depthengine binary &lt;code class=&quot;highlighter-rouge&quot;&gt;libdepthengine.so.1.0&lt;/code&gt; and missing dependencies&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;libdepthengine.so.1.0&lt;/code&gt; is closed-source code for processing the raw depth stream from the camera.
 This binary is included as part of k4a-tools, the &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/Kinect-dk/sensor-sdk-download#linux-installation-instructions&quot;&gt;Azure Kinect SDK Debian package for Ubuntu 18.04&lt;/a&gt;.&lt;/p&gt;

    &lt;p&gt;As a result, you’ll need to install k4a-tools on an Ubuntu 18.04 OS following &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/Kinect-dk/sensor-sdk-download#linux-installation-instructions&quot;&gt;these instructions&lt;/a&gt;, then copy the files installed into &lt;code class=&quot;highlighter-rouge&quot;&gt;/usr/local/lib/x86_64-linux-gnu&lt;/code&gt; onto your Ubuntu 16.04 OS.&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

    &lt;p&gt;In practice, I found that I only needed &lt;code class=&quot;highlighter-rouge&quot;&gt;libdepthengine.so.1.0&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;libstdc++.so.6&lt;/code&gt; from the &lt;code class=&quot;highlighter-rouge&quot;&gt;x86_64-linux-gnu&lt;/code&gt; folder.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Copy the depthengine binary and missing dependencies into the &lt;code class=&quot;highlighter-rouge&quot;&gt;bin/&lt;/code&gt; folder generated by the build in step 3.
    &lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;cp &lt;/span&gt;path/to/x86_64-linux-gnu/libdepthengine.so.1.0 path/to/Azure-Kinect-Sensor-SDK/build/bin/libdepthengine.so.1.0
&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;cp &lt;/span&gt;path/to/x86_64-linux-gnu/libstdc++.so.6 path/to/Azure-Kinect-Sensor-SDK/build/bin/libstdc++.so.6
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Test the installation by running the SDK viewer.&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;
    &lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;path/to/Azure-Kinect-Sensor-SDK/build/bin/k4aviewer
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;If all went well you be able to open your device and see all data streams coming in as below.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;cntr&quot;&gt;
  &lt;img src=&quot;../assets/19-07-19_1.png&quot; /&gt;
  &lt;div class=&quot;caption&quot;&gt;
    Screenshot from k4aviewer
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;To integrate the sensor with ROS, take a look at my follow-up post: &lt;a href=&quot;../azure_kinect_1604_ros/&quot;&gt;How to install ROS drivers for Azure Kinect on Ubuntu 16.04&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;Footnotes&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://askubuntu.com/questions/355565/how-do-i-install-the-latest-version-of-cmake-from-the-command-line&quot;&gt;https://askubuntu.com/questions/355565/how-do-i-install-the-latest-version-of-cmake-from-the-command-line&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;Or find a friend who has a copy :) &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;There are instructions for running the viewer as non-root &lt;a href=&quot;https://github.com/microsoft/Azure-Kinect-Sensor-SDK/blob/develop/docs/usage.md#linux-device-setup&quot;&gt;here&lt;/a&gt; &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Thomas Weng</name></author><category term="robotics" /><summary type="html">Microsoft recently released the Azure Kinect DK sensor, a $399 developer-oriented sensor kit for robotics and mixed reality applications. The kit’s SDK officially supports Windows and Linux 18.04. I’ve managed to get the v1.1 SDK working on Ubuntu 16.04, and have documented the steps below.</summary></entry><entry><title type="html">Using my calendar as a time log</title><link href="http://thomasweng.com/calendar_time_log/" rel="alternate" type="text/html" title="Using my calendar as a time log" /><published>2019-01-05T00:00:00+00:00</published><updated>2019-01-05T00:00:00+00:00</updated><id>http://thomasweng.com/calendar_time_log</id><content type="html" xml:base="http://thomasweng.com/calendar_time_log/">&lt;p&gt;I used to only use my calendar to track upcoming meetings. But then I read Philip Guo’s &lt;a href=&quot;http://www.pgbovine.net/time-management.htm&quot;&gt;blog post on time management&lt;/a&gt;, and was fascinated by how he used his calendar to show where his time went.&lt;/p&gt;

&lt;div class=&quot;cntr&quot;&gt;
  &lt;img src=&quot;../assets/8-postdoc-day.png&quot; width=&quot;30%&quot; /&gt;
  &lt;div class=&quot;caption&quot;&gt;
    The color-coding makes it easy to review at a glance.
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;I decided to try Philip’s calendaring method to see if I was being as productive as I thought. It’s been over a year since I started logging, and I have found it to be great not only for gauging my past productivity, but also for kickstarting changes to how I spend time going forward.&lt;/p&gt;

&lt;p&gt;In the rest of this post, I’ll describe how I log my time and talk about the insights I’ve gained in more detail.&lt;/p&gt;

&lt;h1 id=&quot;logging-is-simple-and-flexible&quot;&gt;Logging is simple and flexible&lt;/h1&gt;

&lt;p&gt;There’s not much to it—after working on a task, I create a calendar entry for the time spent and color-code it. I use Google calendar, but any kind of calendar works. Here is an example of what one of my recent work days looks like.&lt;/p&gt;

&lt;div class=&quot;cntr&quot;&gt;
  &lt;img src=&quot;../assets/8-workday.png&quot; width=&quot;35%&quot; /&gt;
  &lt;div class=&quot;caption&quot;&gt;
    Had a slow morning and missed my bus...didn't want to spend more time looking for an ~ideal~ day
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;I’ve color-coded the activities as follows:&lt;/p&gt;

&lt;table style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;
&lt;colgroup&gt;
&lt;col width=&quot;40%&quot; /&gt;
&lt;col width=&quot;80%&quot; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;!-- &lt;tr class=&quot;header&quot;&gt;
&lt;th&gt;Color&lt;/th&gt;
&lt;th&gt;Category&lt;/th&gt;
&lt;/tr&gt; --&gt;
&lt;/thead&gt;
&lt;tbody&gt;
    &lt;tr&gt;
        &lt;td&gt;
            &lt;span class=&quot;square&quot; style=&quot;background-color: #D98177;&quot;&gt;&lt;/span&gt;
            Pink
        &lt;/td&gt;
        &lt;td&gt;
            Health
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            &lt;span class=&quot;square&quot; style=&quot;background-color: #616161;&quot;&gt;&lt;/span&gt;
            Grey
        &lt;/td&gt;
        &lt;td&gt;
            Travel
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            &lt;span class=&quot;square&quot; style=&quot;background-color: #4C87EC;&quot;&gt;&lt;/span&gt;
            Blue
        &lt;/td&gt;
        &lt;td&gt;
            Coursework
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            &lt;span class=&quot;square&quot; style=&quot;background-color: #3D9ADF;&quot;&gt;&lt;/span&gt; 
            Cyan
        &lt;/td&gt;
        &lt;td&gt;
            Research
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            &lt;span class=&quot;square&quot; style=&quot;background-color: #397D49;&quot;&gt;&lt;/span&gt;
            Green
        &lt;/td&gt;
        &lt;td&gt;Social and Family&lt;/td&gt;
    &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;style&gt;
.square {
    width: 10px;
    display: inline-block;
    height: 10px;
    vertical-align: middle;
    margin-top: -5px;
    margin-right: 3px;
}
&lt;/style&gt;

&lt;p&gt;The system is very flexible. You can use whatever color categories suit you best. Your labels for each activity can be as simple or as descriptive as you like. You can even adapt it for a productivity methodology like David Allen’s &lt;a href=&quot;https://en.wikipedia.org/wiki/Getting_Things_Done&quot;&gt;Getting Things Done&lt;/a&gt; or Cal Newport’s &lt;a href=&quot;http://calnewport.com/books/deep-work/&quot;&gt;Deep Work&lt;/a&gt;. Cal Newport even describes a similar method of logging your time.&lt;/p&gt;

&lt;h1 id=&quot;logging-shows-me-where-my-time-goes-and-how-to-adjust&quot;&gt;Logging shows me where my time goes and how to adjust&lt;/h1&gt;

&lt;p&gt;Since I started using this method, I have a better sense of how I’m spending my time compared to when I relied on my intuition. I’m able to catch patterns of behavior and reinforce them if they are positive, or work on eliminating them if they are negative. For example, I’ve noticed that my energy and focus dips in late afternoon before returning in the evening. Taking a break from work to nap or exercise helps me get through the slump.&lt;/p&gt;

&lt;p&gt;I also have a better sense of the present. Logging each task helps me be more deliberate about each activity I start, and makes me aware of deviations from my planned schedule quickly, so that I don’t reach the end of the day and realize too late that I went off track.&lt;/p&gt;

&lt;p&gt;Some may think it takes a lot of work to log time like this, but it really doesn’t take long. To me, the benefit of having a better handle on my time is worth the few moments it takes to do the logging.&lt;/p&gt;

&lt;h1 id=&quot;some-final-notes&quot;&gt;Some final notes&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;If there are events that fit into multiple categories, I don’t worry too much about it and just pick one.&lt;/li&gt;
  &lt;li&gt;I work in thirty minute chunks, so I set the default event duration in Google calendar to thirty minutes instead of an hour.&lt;/li&gt;
  &lt;li&gt;I also generally try not to have overlapping things in my calendar. If there are conflicting events, I will cancel my appointment with the less important one and move it off my calendar or gray it out. I can’t be in two places at the same time anyway.&lt;/li&gt;
  &lt;li&gt;Unlike Philip Guo, I don’t keep track of my efficiency level for each task. I found it both difficult and distracting to assess how efficient I was.&lt;/li&gt;
  &lt;li&gt;In a way, this is similar to the post I wrote about &lt;a href=&quot;https://thomasweng.com/journaling/&quot;&gt;how I journal&lt;/a&gt; in that it’s about recording things. When I started using this calendar, I stopped journaling my day-to-day items in as much detail because the calendar serves that purpose now. But I’ll still put my thoughts and feelings in my journal.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;i&gt;Many thanks to &lt;a href=&quot;https://www.cherieho.com/&quot;&gt;Cherie Ho&lt;/a&gt; and &lt;a href=&quot;https://www.ri.cmu.edu/ri-people/ada-taylor/&quot;&gt;Ada Taylor&lt;/a&gt; for reviewing this post!&lt;/i&gt;&lt;/p&gt;</content><author><name>Thomas Weng</name></author><category term="productivity" /><summary type="html">I used to only use my calendar to track upcoming meetings. But then I read Philip Guo’s blog post on time management, and was fascinated by how he used his calendar to show where his time went.</summary></entry><entry><title type="html">Staying on top of email</title><link href="http://thomasweng.com/staying_on_top_of_email/" rel="alternate" type="text/html" title="Staying on top of email" /><published>2018-11-03T00:00:00+00:00</published><updated>2018-11-03T00:00:00+00:00</updated><id>http://thomasweng.com/staying_on_top_of_email</id><content type="html" xml:base="http://thomasweng.com/staying_on_top_of_email/">&lt;p&gt;I find it hard to be productive when my inbox is cluttered with emails. It’s easy to lose track of high-priority tasks in a messy inbox.&lt;/p&gt;

&lt;div class=&quot;cntr&quot;&gt;
  &lt;img src=&quot;../assets/7-cluttered.png&quot; /&gt;
  &lt;div class=&quot;caption&quot;&gt;
    Screenshot of someone's inbox from the Internet. 13k unread emails = instant anxiety.
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;To keep a tidy inbox, I aim for Inbox Zero daily. That means for each email:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;If there’s a task that can be done in a minute, I’ll do it immediately and archive it.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If there’s a task to be done today, I’ll add it to my to-do list and then &lt;a href=&quot;https://support.google.com/mail/answer/7622010?co=GENIE.Platform%3DDesktop&amp;amp;hl=en&quot;&gt;snooze&lt;/a&gt; the email.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If the task isn’t urgent, I’ll just snooze it to whenever I can/need to do it.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;cntr&quot;&gt;
  &lt;img src=&quot;../assets/7-clean.png&quot; /&gt;
  &lt;div class=&quot;caption&quot;&gt;
    Much better!
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;I don’t always achieve an empty inbox following this approach, especially when a lot of things are happening at once. The goal may also not always be to clear all emails, if you need some handy for your task for example.&lt;/p&gt;

&lt;p&gt;Though I tried to keep my approach lightweight, there’s definitely room for improvement. For example, I’m still experimenting to find a good to-do list workflow. I could be more disciplined about when I check my email to avoid interruptions in my work. So far, though, this method is pretty effective in helping me stay organized.&lt;/p&gt;</content><author><name>Thomas Weng</name></author><category term="productivity" /><summary type="html">I find it hard to be productive when my inbox is cluttered with emails. It’s easy to lose track of high-priority tasks in a messy inbox.</summary></entry><entry><title type="html">Setting up TeX math rendering for your blog or website</title><link href="http://thomasweng.com/setting_up_tex/" rel="alternate" type="text/html" title="Setting up TeX math rendering for your blog or website" /><published>2018-04-26T00:00:00+00:00</published><updated>2018-04-26T00:00:00+00:00</updated><id>http://thomasweng.com/setting_up_tex</id><content type="html" xml:base="http://thomasweng.com/setting_up_tex/">&lt;p&gt;Setting up \(\TeX\)math typesetting on your website is one of those tasks that can seem really difficult if you don’t know what to look for. Here’s a simple way to do it.&lt;/p&gt;

&lt;p&gt;I used Khan Academy’s &lt;a href=&quot;https://khan.github.io/KaTeX/&quot;&gt;KaTeX&lt;/a&gt; typesetting library for my blog. KaTeX is fast, self-contained, and works largely as you would expect. Here are the instructions:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Include KaTeX on your site by adding the &lt;a href=&quot;https://github.com/Khan/KaTeX/blob/master/contrib/auto-render/README.md&quot;&gt;required reference tags and scripts&lt;/a&gt; to your html template&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. See 
&lt;a href=&quot;https://github.com/thomasweng15/thomasweng15.github.io/commit/a8ae4f214dd8bec31e29c62f3cdc79d2e9b761f8&quot;&gt;this commit&lt;/a&gt; for the changes I made to get it working on this blog.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Typeset math by enclosing your notation within &lt;code class=&quot;text&quot;&gt;\\(&lt;/code&gt; and &lt;code class=&quot;text&quot;&gt;\\)&lt;/code&gt; for inline typesetting, or &lt;code class=&quot;text&quot;&gt;\\[&lt;/code&gt; and &lt;code class=&quot;text&quot;&gt;\\]&lt;/code&gt; for typesetting on a separate line.&lt;/p&gt;

    &lt;p&gt;For example, with inline typesetting, &lt;code class=&quot;text&quot;&gt;\\(\alpha\\)&lt;/code&gt;, becomes \(\alpha\). With non-inline typesetting, &lt;code class=&quot;text&quot;&gt;\\[x^2 + y^2 + z^2 = r^2\\]&lt;/code&gt; becomes: \[x^2 + y^2 + z^2 = r^2\]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If you have any rendering issues, check your console for error messages. Also take a look at the full documentation on &lt;a href=&quot;https://github.com/Khan/KaTeX&quot;&gt;Github&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
&lt;p&gt;Footnotes&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;You can also download these files and host them on your server directly instead of getting them from the cdn. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Thomas Weng</name></author><category term="blogging" /><summary type="html">Setting up \(\TeX\)math typesetting on your website is one of those tasks that can seem really difficult if you don’t know what to look for. Here’s a simple way to do it.</summary></entry><entry><title type="html">Automating C++ builds in ROS</title><link href="http://thomasweng.com/automating_C++_builds_ros/" rel="alternate" type="text/html" title="Automating C++ builds in ROS" /><published>2017-09-09T00:00:00+00:00</published><updated>2017-09-09T00:00:00+00:00</updated><id>http://thomasweng.com/automating_C++_builds_ros</id><content type="html" xml:base="http://thomasweng.com/automating_C++_builds_ros/">&lt;p&gt;If you’re working on a C++ ROS project, you probably run &lt;code class=&quot;highlighter-rouge&quot;&gt;catkin build&lt;/code&gt; every time you make a change. This is tedious and takes you out of your programming flow. It’s especially annoying when your build fails multiple times due to small errors. I’m a big proponent of keeping the iteration loop as small as possible.&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;To fix this, I’ve automated the build process to build when saving a file! No more manual building :).&lt;/p&gt;

&lt;p&gt;Here’s how it works. I’ve written a shell script called &lt;code class=&quot;highlighter-rouge&quot;&gt;builder.sh&lt;/code&gt; that kicks off a build for you every time you save a file in your source directories. If the build fails, it will output the error. If the build succeeds, it’ll print a success message. Here’s an example of a build failure, followed by success:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ bash builder.sh
Setting up watches.
Watches established.
octomapper.cpp modified, rebuilding...
_______________________________________________________________________________
Errors     &amp;lt;&amp;lt; perception:make /home/tweng/catkin_ws/logs/perception/build.make.1447.log
/home/tweng/catkin_ws/src/ros-project/src/perception/src/octomapper.cpp: In member function ‘void perception::Octomapper::publish_octomap(octomap::OcTree*)’:
/home/tweng/catkin_ws/src/ros-project/src/perception/src/octomapper.cpp:99:3: error: ‘pub’ was not declared in this scope
   pub.publish(octomap_msg);
   ^
make[2]: *** [CMakeFiles/perception_octomapper.dir/src/octomapper.cpp.o] Error 1
make[1]: *** [CMakeFiles/perception_octomapper.dir/all] Error 2
make: *** [all] Error 2
cd /home/tweng/catkin_ws/build/perception; catkin build --get-env perception | catkin env -si  /usr/bin/make --jobserver-fds=6,7 -j; cd -
...............................................................................
Failed     &amp;lt;&amp;lt; perception:make           [ Exited with code 2 ]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;There is syntax highlighting in your terminal which makes this output more readable.&lt;/p&gt;

&lt;p&gt;After fixing the issue and saving, the build runs again automatically:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;octomapper.cpp modified, rebuilding...
[build] Summary: All 2 packages succeeded!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It’s fairly simple to get this set up for your workspace. You’ll need to:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Get the script from this Github gist: &lt;a href=&quot;https://gist.github.com/thomasweng15/db12693f957ecafb6eed3bb011db37a3#file-builder-sh&quot;&gt;builder.sh&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Configure it to watch your workspace directories&lt;/li&gt;
  &lt;li&gt;Run it in a terminal using &lt;code class=&quot;highlighter-rouge&quot;&gt;bash builder.sh&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Start coding and enjoying ~build-on-save~&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;but-wait-theres-more-roslaunch-auto-restart&quot;&gt;But wait, there’s more: &lt;code class=&quot;highlighter-rouge&quot;&gt;roslaunch&lt;/code&gt; auto-restart!&lt;/h1&gt;

&lt;p&gt;After your build completes, you’ll probably need to run or restart your ROS nodes to test your changes. That’s another manual step we can automate.&lt;/p&gt;

&lt;p&gt;This time, a script called &lt;code class=&quot;highlighter-rouge&quot;&gt;launcher.sh&lt;/code&gt; runs your project’s &lt;code class=&quot;highlighter-rouge&quot;&gt;roslaunch&lt;/code&gt; command and listens periodically to make sure your ROS nodes are alive. As you make changes and get a successful build, &lt;code class=&quot;highlighter-rouge&quot;&gt;builder.sh&lt;/code&gt; – the original script – sends a signal to kill your ROS nodes.&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; When the ROS nodes die, &lt;code class=&quot;highlighter-rouge&quot;&gt;launcher.sh&lt;/code&gt; will automatically restart them, grabbing your newest build. Here’s an example of what restarting looks like:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ bash launcher.sh
Launching roslaunch
... logging to /home/tweng/.ros/log/3674ab20-73be-11e7-b57f-b8ca3ab4b589/roslaunch-silverarm-15112.log
Checking log directory for disk usage. This may take awhile.
Press Ctrl-C to interrupt
Done checking log file disk usage. Usage is &amp;lt;1GB.

started roslaunch server http://localhost:39545/

...

/process_cloud_main shutdownCallback:163: Shutdown request received.
/process_cloud_main shutdownCallback:164: Reason given for shutdown: [user request]
================================================================================REQUIRED process [process_cloud_main-1] has died!
process has finished cleanly
log file: /home/tweng/.ros/log/3674ab20-73be-11e7-b57f-b8ca3ab4b589/process_cloud_main-1*.log
Initiating shutdown!
================================================================================
[publish_saved_cloud-3] killing on exit
[person_broadcaster-2] killing on exit
[process_cloud_main-1] killing on exit
shutting down processing monitor...
... shutting down processing monitor complete
done
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;launcher.sh&lt;/code&gt; notices that the node has gone down and triggers a restart:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Launching roslaunch
... logging to /home/tweng/.ros/log/3674ab20-73be-11e7-b57f-b8ca3ab4b589/roslaunch-silverarm-30141.log
Checking log directory for disk usage. This may take awhile.
Press Ctrl-C to interrupt
Done checking log file disk usage. Usage is &amp;lt;1GB.

started roslaunch server http://localhost:34414/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You can get &lt;code class=&quot;highlighter-rouge&quot;&gt;launcher.sh&lt;/code&gt; &lt;a href=&quot;https://gist.github.com/thomasweng15/db12693f957ecafb6eed3bb011db37a3#file-launcher-sh&quot;&gt;here&lt;/a&gt;. You’d run it in a terminal (&lt;code class=&quot;highlighter-rouge&quot;&gt;bash launcher.sh&lt;/code&gt;), just like the first one.&lt;/p&gt;

&lt;p&gt;If your builds take a lot of processing power and/or take a long time, you may need to make adjustments to this script. I personally haven’t had any problems rebuilding on every save. One option if you do have problems is to rebuild only the package you are working on, and not the whole workspace.&lt;/p&gt;

&lt;p&gt;Hope this helps and you find it useful!&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;Footnotes&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Originally inspired by Brett Victor’s talk, “Inventing on Principle.” Check it out a recording of it here: &lt;a href=&quot;https://vimeo.com/36579366&quot;&gt;video link&lt;/a&gt;. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;I set the main node with the &lt;code class=&quot;highlighter-rouge&quot;&gt;required=true&lt;/code&gt; attribute in my launch file so I only need to kill that node to stop the others. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Thomas Weng</name></author><category term="productivity" /><category term="robotics" /><summary type="html">If you’re working on a C++ ROS project, you probably run catkin build every time you make a change. This is tedious and takes you out of your programming flow. It’s especially annoying when your build fails multiple times due to small errors. I’m a big proponent of keeping the iteration loop as small as possible.1 Originally inspired by Brett Victor’s talk, “Inventing on Principle.” Check it out a recording of it here: video link. &amp;#8617;</summary></entry><entry><title type="html">How I Journal</title><link href="http://thomasweng.com/journaling/" rel="alternate" type="text/html" title="How I Journal" /><published>2017-05-30T00:00:00+00:00</published><updated>2017-05-30T00:00:00+00:00</updated><id>http://thomasweng.com/journaling</id><content type="html" xml:base="http://thomasweng.com/journaling/">&lt;p&gt;Can you remember, off the top of your head, what you were doing at this date and time two months ago? What about just two weekends ago? It is surprising to me how rarely people journal when our memories are so ephemeral. We have new thoughts, experiences, and conversations every day, yet we save and reflect on so few of them.&lt;/p&gt;

&lt;p&gt;Journaling is one effective way to take control of your life and memories. Although taking photos and videos are more common ways to keep track of what you do or see, I’ve found writing to be more effective when it comes to reflecting on my life and staying organized.&lt;/p&gt;

&lt;h1 id=&quot;forming-habits&quot;&gt;Forming habits&lt;/h1&gt;

&lt;p&gt;People I’ve spoken to on this subject are generally receptive to the concept of journaling, but many find it difficult to prioritize the activity and keep a routine. I personally journal about once a week, filling in several days at a time. After a few months, it’s fulfilling to go back and revisit old entries. It’s amazing how a few short sentences can bring you back to an amazing conversation with a close friend, or your mood on a sunny, relaxing day, for example.&lt;/p&gt;

&lt;p&gt;For me, one of the biggest starting hurdles was choosing the proper journaling medium. There are countless apps out there, but many of them have inconvenient tradeoffs. Apps often make it difficult to export your data, get in your way with ads, or keep useful features behind paywalls. There’s always pen and paper, but while writing by hand can be relaxing, it is also slower than typing, difficult to search through, and hard to preserve through the years.&lt;/p&gt;

&lt;h1 id=&quot;journaling-in-markdown&quot;&gt;Journaling in Markdown&lt;/h1&gt;

&lt;p&gt;My solution for the past year and a half has been to journal digitally in Markdown files. Markdown is designed to be easy-to-read, easy-to-write, and it avoids the pitfalls I mentioned above. Here’s a example of how I journal, albeit somewhat contrived and with less detail:&lt;/p&gt;

&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;
## Mon 29
* __exercise__ 7 minute workout
* Skyped with X. It was the first time we caught up in a while! We talked about our living situations, our jobs, and what we've been spending our spare time doing these past few months.
* Met up with Y at Cafe Cesura. Worked on a blog post about journaling.
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Which converts into the following HTML:&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;mon-29&quot;&gt;Mon 29&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;exercise&lt;/strong&gt; 7 minute workout&lt;/li&gt;
  &lt;li&gt;Skyped with X. It was the first time we caught up in a while! We talked about our living situations, our jobs, and what we’ve been spending our spare time doing these past few months.&lt;/li&gt;
  &lt;li&gt;Met up with Y. at Cafe Cesura. Worked on a blog post about journaling.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;Markdown’s lightweight structure provides both organization and flexibility. I generally use headers for dates, followed by bullet points describing each significant event of the day. I keep each month in a separate file, and each year of files in a distinct folder.&lt;/p&gt;

&lt;p&gt;I also use tags like &lt;code class=&quot;text&quot;&gt;__exercise__&lt;/code&gt; above to mark certain categories of events or thoughts. This has an added benefit of being easily searchable in Atom, my text editor of choice for journaling.&lt;/p&gt;

&lt;div class=&quot;cntr&quot;&gt;
  &lt;img src=&quot;../assets/4-search.png&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;
Atom also provides a handy Markdown preview:
&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;cntr&quot;&gt;
  &lt;img src=&quot;../assets/4-preview.png&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;
Using Markdown, I can write faster than on paper, search through my notes quickly, and save backup copies easily. I don’t have to rely on any apps, nor give any third parties ownership of my data.&lt;/p&gt;

&lt;h1 id=&quot;a-year-and-a-half-of-markdown&quot;&gt;A year and a half of Markdown&lt;/h1&gt;
&lt;p&gt;As I mentioned earlier, I’ve been journaling in markdown for the past 1.5 years, and I’m really enjoying the setup. I journal approximately once a week, but I’ve been trying to increase the frequency. The amount of information I retain about a particular day significantly diminishes by the third passing day.&lt;/p&gt;

&lt;h2 id=&quot;perspectives-on-time-and-value&quot;&gt;Perspectives on time and value&lt;/h2&gt;

&lt;p&gt;Journaling has given me a much better higher-level understanding of where my time goes and more importantly, what I value. Keeping the one folder per year structure I have now, I’ll have 60 folders of journal files, give or take, by the end of my life. That’s not a lot, all things considered, and made me think about what I want to accomplish and record in my lifetime.&lt;/p&gt;

&lt;h2 id=&quot;handwritten-notes-are-still-cool&quot;&gt;Handwritten notes are still cool&lt;/h2&gt;

&lt;p&gt;Digital journaling hasn’t completely replaced pen and paper. I still take handwritten notes in pocket notepads to remember things to do, books to read, or random thoughts. More often than not, I’ll transfer the interesting portions into my journal.&lt;/p&gt;

&lt;h1 id=&quot;whats-next&quot;&gt;What’s next&lt;/h1&gt;
&lt;p&gt;There are other sources of data besides journaling that I want to pull together to form a richer picture. Photos, calendars, conversations, and geotags would add a lot of context to my journal.&lt;/p&gt;

&lt;p&gt;To this end, I started writing a parser in Python for the Markdown-generated HTML files. The output is a Python object, which I can work with programmatically. As an example use case, I’ll be able to match up a given date with photos taken on that date in Google Photos. Ultimately, I hope to put together a simple webpage to show what I was up to on a given date in every year of my life.&lt;/p&gt;

&lt;p&gt;&lt;i&gt;If you liked this post, you may also like this one I wrote on &lt;a href=&quot;https://thomasweng.com/calendar_time_log/&quot;&gt;how I keep a calendar&lt;/a&gt;.&lt;/i&gt;&lt;/p&gt;</content><author><name>Thomas Weng</name></author><category term="productivity" /><category term="popular" /><summary type="html">Can you remember, off the top of your head, what you were doing at this date and time two months ago? What about just two weekends ago? It is surprising to me how rarely people journal when our memories are so ephemeral. We have new thoughts, experiences, and conversations every day, yet we save and reflect on so few of them.</summary></entry><entry><title type="html">Getting Started with Tensorflow</title><link href="http://thomasweng.com/tensorflow_getting_started/" rel="alternate" type="text/html" title="Getting Started with Tensorflow" /><published>2017-02-10T00:00:00+00:00</published><updated>2017-02-10T00:00:00+00:00</updated><id>http://thomasweng.com/tensorflow_getting_started</id><content type="html" xml:base="http://thomasweng.com/tensorflow_getting_started/">&lt;p&gt;I took some time out this past weekend to work through an introductory machine learning talk on building models using Tensorflow. Within a few hours, I coded up a model classifying handwritten digits from the MNIST dataset with 99.5% accuracy! Considering that the accuracy of cutting edge research models currently hover at around 99.7%, my model was a pretty good result for just a few hours of development.&lt;/p&gt;

&lt;p&gt;The resource I relied on to ramp up was &lt;a href=&quot;https://cloud.google.com/blog/big-data/2017/01/learn-tensorflow-and-deep-learning-without-a-phd&quot;&gt;Google’s crash course through Tensorflow&lt;/a&gt;, presented by Martin Gorner at &lt;a href=&quot;https://devoxx.com/&quot;&gt;Devoxx&lt;/a&gt;. The talk starts with a simple one-layer neural network, building quickly into multi-layer neural nets, convolutional neural nets, recurrent neural nets, and a collection of optimization techniques (e.g. learning rate decay, dropout, batch normalization).&lt;/p&gt;

&lt;p&gt;I took the time to write out the code and get things working on my machine. That took longer than simply watching the video, but it deepened my understanding and guaranteed that I didn’t gloss over any important details. The slides from the talk included most of the code required for the models, but I did need to fill in some of the gaps. When I got stuck, I referenced the complete model at the &lt;a href=&quot;https://github.com/martin-gorner/tensorflow-mnist-tutorial&quot;&gt;Github repo&lt;/a&gt; Gorner created for this talk.&lt;/p&gt;

&lt;p&gt;Gorner’s presentation glosses over the math behind concepts presented in order to focus on model building. I think this was a smart tradeoff. Having spent quite a bit of time taking courses and learning the math powering machine learning, the details of how the math works would probably be too involved for a short talk. And when it comes to actually building models, Tensorflow does the heavy lifting and abstracts the mathematical details away anyway.&lt;/p&gt;

&lt;p&gt;Of course, the math does become more relevant as one continues working with ML. I’m sure I wouldn’t have picked things up so quickly with Tensorflow had I not already studied the background concepts.&lt;/p&gt;

&lt;p&gt;I’m looking forward to playing more with Tensorflow and learning about what’s going on under the hood. I’ll be keeping up with the math through online resources – courses, textbooks, and hopefully papers. Most of all, I’m excited to take the training wheels off soon and start building my own models from scratch!&lt;/p&gt;</content><author><name>Thomas Weng</name></author><category term="machine learning" /><summary type="html">I took some time out this past weekend to work through an introductory machine learning talk on building models using Tensorflow. Within a few hours, I coded up a model classifying handwritten digits from the MNIST dataset with 99.5% accuracy! Considering that the accuracy of cutting edge research models currently hover at around 99.7%, my model was a pretty good result for just a few hours of development.</summary></entry><entry><title type="html">Robotics Day at Microsoft</title><link href="http://thomasweng.com/microsoft_robotics_day/" rel="alternate" type="text/html" title="Robotics Day at Microsoft" /><published>2017-02-01T00:00:00+00:00</published><updated>2017-02-01T00:00:00+00:00</updated><id>http://thomasweng.com/microsoft_robotics_day</id><content type="html" xml:base="http://thomasweng.com/microsoft_robotics_day/">&lt;p&gt;When it comes to applying for opportunities, I’m no different from everyone else: I always get anxious. But preparing an application is often a great way to make your work presentable and gauge your progress.&lt;/p&gt;

&lt;p&gt;Earlier this month, I heard about Robotics Day, an all-day event at Microsoft consisting of a series of talks, guided tours of Microsoft Research labs, and an expo showcasing robots built by hobbyist employees. The organizers sent out a call for volunteers and an application for prospective expo presenters.&lt;/p&gt;

&lt;p&gt;This event was right up my alley. I was excited at the prospect of connecting with other MS folks doing robotics. I had even been building my own robot these past few months, so the expo was the perfect opportunity to show it off! However, I didn’t feel confident about applying for the expo, because I feared my work wouldn’t meet the same bar as other presenters. I didn’t want to stick out and look like I didn’t know what I was doing.&lt;/p&gt;

&lt;p&gt;I wavered for a bit about applying, but ultimately I figured that I would give it my best shot and let the organizers decide if I made the cut. I also signed up to be a volunteer, so that in case of rejection, I could at least help out and get to know the organizers.&lt;/p&gt;

&lt;p&gt;In the end, I got to do it all: I volunteered, attended the talks, and presented at the expo! I’ll focus on my experience at the expo here, so that this post doesn’t get too long.&lt;/p&gt;

&lt;h1 id=&quot;at-the-expo&quot;&gt;At the expo&lt;/h1&gt;
&lt;p&gt;My presentation naturally focused on Rover, the robot that I have been building and programming for almost half a year. Here is a picture of the bot:&lt;/p&gt;

&lt;div class=&quot;cntr&quot;&gt;
  &lt;a data-flickr-embed=&quot;true&quot; href=&quot;https://www.flickr.com/photos/145491926@N08/32280109700/in/dateposted-public/&quot; title=&quot;rover&quot;&gt;&lt;img src=&quot;https://c1.staticflickr.com/1/714/32280109700_3c62f38457_c.jpg&quot; width=&quot;400&quot; height=&quot;400&quot; alt=&quot;rover&quot; /&gt;&lt;/a&gt;&lt;script async=&quot;&quot; src=&quot;//embedr.flickr.com/assets/client-code.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;p&gt;I am building Rover to be an intelligent, mobile agent, kind of like a pet. A big part of the fun is seeing how much intelligence I can build using off-the-shelf hardware and open-source software. I’ll be writing up a more detailed post on building and designing Rover soon.&lt;/p&gt;

&lt;p&gt;Rover is still a work in progress, so I put together several materials to aid me with the presentation. Here’s a picture of my booth setup:&lt;/p&gt;

&lt;div class=&quot;cntr&quot;&gt;
  &lt;a data-flickr-embed=&quot;true&quot; href=&quot;https://www.flickr.com/photos/145491926@N08/32455305401/in/dateposted-public/&quot; title=&quot;IMG_8918&quot;&gt;&lt;img src=&quot;https://c1.staticflickr.com/1/564/32455305401_9b0a127ced_c.jpg&quot; width=&quot;450&quot; height=&quot;600&quot; alt=&quot;IMG_8918&quot; /&gt;&lt;/a&gt;&lt;script async=&quot;&quot; src=&quot;//embedr.flickr.com/assets/client-code.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;p&gt;Here’s an online version of the poster on the wall; click for a full page view:&lt;/p&gt;

&lt;div class=&quot;cntr&quot;&gt;
  &lt;a target=&quot;\_blank&quot; href=&quot;../assets/2-diag.png&quot;&gt;
    &lt;img src=&quot;../assets/2-diag.png&quot; style=&quot;width: 90%; height: 90%;&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;h2 id=&quot;presentation-materials&quot;&gt;Presentation materials&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Poster.&lt;/strong&gt; On the poster, I mapped out the project goals, system design, roadmap, and key challenges, and other topics. It served as a handy reference when people asked questions, as I could point out the relevant details quickly.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Video.&lt;/strong&gt; I played a short video on loop with clips demoing Rover at different stages of development. I also included demos of robots on the market aiming to be intelligent agents for comparison.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Contact info.&lt;/strong&gt; I laid out some paper strips with project links and my contact information for people to take, in case they wanted to connect with me later.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-presenting-went&quot;&gt;How presenting went&lt;/h2&gt;
&lt;p&gt;The expo lasted for two hours, and lots of people stopped by. I ended up having virtually no downtime, which was great! It was rewarding to see people checking out my robot, looking at my presentation materials, and asking me questions about what I had built.&lt;/p&gt;

&lt;p&gt;It was interesting to observe what drew people’s attention. My robot was powered on but stationary, and many people were drawn to the booth by the spinning LIDAR on the robot. It turned out that few people knew that fairly inexpensive LIDARs were available for hobby robotics. Once people were engaged, I pitched my vision for Rover as an intelligent pet-like robot, and described the progress I was making towards that goal.&lt;/p&gt;

&lt;p&gt;There were a lot of other cool robots on display, like battle robots, mobile robots made with bicycle wheels, and even a foosball-playing robot! All the presenters were really friendly, and we all had a great time demoing our creations.&lt;/p&gt;

&lt;h1 id=&quot;what-i-learned&quot;&gt;What I learned&lt;/h1&gt;

&lt;p&gt;My biggest takeaway from this experience is realizing how important it is to practice pitching my ideas to other people. Though I had been working on my robot for months, I had very little to show for it besides the physical robot.&lt;/p&gt;

&lt;p&gt;Preparing to show my project to other people forced me to distill the nebulous thoughts I had been working with into well-formed concepts. Showing my work also allowed me to gauge how people responded to Rover and get their feedback. And practicing my pitch helped me keep my communication skills sharp.&lt;/p&gt;

&lt;p&gt;Finally, I’m learning to become less anxious about applying to things. I want to treat applications more as learning opportunities rather than tests. If I feel overly anxious, not only is it counter productive, but it probably means that I’m overestimating how much I’ll lose if I get rejected. It’s better to just keep trying, learning, and growing.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;Thanks for reading, and best wishes to you on whatever projects or opportunities you are working towards! Stay tuned for more details about Rover.&lt;/p&gt;</content><author><name>Thomas Weng</name></author><category term="robotics" /><summary type="html">When it comes to applying for opportunities, I’m no different from everyone else: I always get anxious. But preparing an application is often a great way to make your work presentable and gauge your progress.</summary></entry></feed>